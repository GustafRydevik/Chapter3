
R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.1.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ####Use 
> #bash > nohup R --vanilla --slave --args seed 1000 burn.in 25000 adapt.iter 500 Set.endtime 63 nreps 200 < SerologyDataSim_btv.R > nohup2.out 2>&1&
> ##to run in girion
> 
> ###parameters
> 
> ####Generating various simulated testing datasets, using functions from eventGenerators.R and Labdatagenerator.
> 
> ##Parameters for using the batch package for multiple parallell runs
> 
> 
> #Global parameters
> got.mdrive<-length(dir("M:"))>0
> is.win<-grepl("w32",R.Version()$platform)
> is.girion<-sum(grep("girion",system("hostname",intern=TRUE)))
> dropbox.sac<-"C:/Documents and Settings/GRydevik/My Documents/Dropbox"
> dropbox.bioss<-"D:\\Dropbox"
> dropbox.osx<-"/Users/gustafrydevik/Dropbox"
> dropbox.girion<-"/home/gustaf/SeroNA_temp"
> dropbox.path<-c(dropbox.osx,dropbox.sac,dropbox.bioss)[got.mdrive+is.win+1]
> if(is.girion){dropbox.path<-dropbox.girion}
> #sim.dir<-"D:/simulations/"
> #sim.dir<-paste(dropbox.path,"/simulations",sep="")
> sim.dir<-"/Users/gustafrydevik/simulations/Chapter3/"
> if(is.girion)sim.dir<-file.path(dropbox.path,"simulations/")
> ##Project specific parameters
> project.path<-file.path(dropbox.path,"PhD folder/Chapter3")
> if(is.girion){project.path<-dropbox.girion}
> data.path<-file.path(project.path,"Data")
> script.path<-file.path(project.path,"Scripts")
> output.path<-file.path(project.path,"Output")
> 
> lapply(dir(file.path(dropbox.path,"GusLib"),full.names=T),source)
[[1]]
[[1]]$value
function (Package, ...) 
{
    if (!suppressWarnings(require(as.character(substitute(Package)), 
        character.only = TRUE, quietly = TRUE, ...))) {
        Package <- as.character(substitute(Package))
        install.packages(Package, ...)
        library(Package, character.only = TRUE)
    }
}

[[1]]$visible
[1] FALSE


[[2]]
[[2]]$value
function (Package, mirror = "http://stat.ethz.ch/CRAN", ...) 
{
    if (!suppressWarnings(require(as.character(substitute(Package)), 
        character.only = TRUE, quietly = TRUE, ...))) {
        Package <- as.character(substitute(Package))
        install.packages(Package, repos = mirror, ...)
        library(Package, character.only = TRUE)
    }
}

[[2]]$visible
[1] FALSE


[[3]]
[[3]]$value
function (D, file = "ggmcmc-output.pdf", family = NA, param.page = 5, 
    width = 7, height = 10, ...) 
{
    if (!is.na(family)) {
        D <- get_family(D, family = family)
    }
    n.param <- length(unique(D$Parameter))
    if (attributes(D)$nParameters <= param.page) {
        cat("Plotting histograms\n")
        print(ggs_histogram(D))
        cat("Plotting density plots\n")
        print(ggs_density(D))
        cat("Plotting traceplots\n")
        print(ggs_traceplot(D))
        cat("Plotting running means\n")
        print(ggs_running(D))
        cat("Plotting comparison of partial and full chain\n")
        print(ggs_compare_partial(D))
        cat("Plotting autocorrelation plots\n")
        print(ggs_autocorrelation(D))
    }
    else {
        old.atrib <- attributes(D)
        n.pages <- ceiling(n.param/param.page)
        parameters <- unique(D$Parameter)
        D.parameters <- data.frame(Parameter = parameters, page = as.numeric(as.character(gl(n.pages, 
            param.page, length = length(parameters)))))
        new.atrib <- old.atrib
        D <- merge(D, D.parameters)
        D <- D[, c(old.atrib$names, "page")]
        new.atrib$names <- c(old.atrib$names, "page")
        attributes(D) <- new.atrib
        cat("Plotting histograms\n")
        for (p in 1:n.pages) print(ggs_histogram(D[D$page == 
            p, ]))
        cat("Plotting density plots\n")
        for (p in 1:n.pages) print(ggs_density(D[D$page == p, 
            ]))
        cat("Plotting traceplots\n")
        for (p in 1:n.pages) print(ggs_traceplot(D[D$page == 
            p, ]))
        cat("Plotting running means\n")
        for (p in 1:n.pages) print(ggs_running(D[D$page == p, 
            ]))
        cat("Plotting comparison of partial and full chain\n")
        for (p in 1:n.pages) print(ggs_compare_partial(D[D$page == 
            p, ]))
        cat("Plotting autocorrelation plots\n")
        for (p in 1:n.pages) print(ggs_autocorrelation(D[D$page == 
            p, ]))
    }
    cat("Plotting crosscorrelation plot\n")
    print(ggs_crosscorrelation(D))
    cat("Plotting Potential Scale Reduction Factors\n")
    print(ggs_Rhat(D))
    cat("Plotting Geweke Diagnostic\n")
    print(ggs_geweke(D))
    cat("Plotting caterpillar plot\n")
    Parameter.family <- gsub("\\[.+\\]", "", D$Parameter)
    n.family.members <- apply(ifelse(table(D$Parameter, Parameter.family) > 
        0, 1, 0), 2, sum)
    for (f in unique(Parameter.family)) {
        if (n.family.members[f] > 1) {
            print(ggs_caterpillar(D, family = f, horizontal = TRUE) + 
                labs(title = f))
        }
    }
}

[[3]]$visible
[1] FALSE


[[4]]
[[4]]$value
function (xpos, ypos, npoints) 
{
    points.dist <- sqrt(diff(xpos)^2 + diff(ypos)^2)
    path.cumlength <- cumsum(points.dist)
    equaldist.cumlength <- seq(0, tail(path.cumlength, 1), length.out = npoints - 
        1)
    stddist <- equaldist.cumlength[2]
    Interpol.points <- list(x = vector(length = npoints, mode = "numeric"), 
        y = vector(length = npoints, mode = "numeric"))
    Interpol.points$x[1] = xpos[1]
    Interpol.points$y[1] = ypos[1]
    for (i in 2:(npoints - 5)) {
        start.point = c(Interpol.points$x[i - 1], Interpol.points$y[i - 
            1])
        ndx <- which(path.cumlength > equaldist.cumlength[i - 
            1] & path.cumlength <= equaldist.cumlength[i + 5])
        x.lm <- xpos[ndx + 1] - start.point[1]
        y.lm <- ypos[ndx + 1] - start.point[2]
        cos.values <- x.lm/sqrt(x.lm^2 + y.lm^2)
        Angle = mean(((y.lm < 0) * 2 * pi) + acos(cos.values) * 
            sign(y.lm))
        Ydist = sin(Angle) * stddist
        Xdist = cos(Angle) * stddist
        Next.point <- start.point + c(Xdist, Ydist)
        Interpol.points$x[i] = Next.point[1]
        Interpol.points$y[i] = Next.point[2]
    }
    return(Interpol.points)
}

[[4]]$visible
[1] FALSE


[[5]]
[[5]]$value
function (x) 
x & !is.na(x)

[[5]]$visible
[1] FALSE


[[6]]
[[6]]$value
function (x) 
x & !is.na(x)

[[6]]$visible
[1] FALSE


[[7]]
[[7]]$value
function (Wanted.device = "png", fileEnding = NULL, ...) 
{
    dots <- list(...)
    ending <- Wanted.device
    Wanted.device <- get(Wanted.device)
    if (!is.null(fileEnding)) 
        ending <- fileEnding
    generated.device <- function(File, ...) {
        dots2 <- list(...)
        File <- paste(File, ending, sep = ".")
        dots[which(names(dots) %in% names(dots2))] <- NULL
        if (ending != "pdf") {
            do.call(Wanted.device, c(filename = File, dots, dots2))
        }
        if (ending == "pdf") {
            do.call(Wanted.device, c(file = File, dots, dots2))
        }
    }
    return(generated.device)
}

[[7]]$visible
[1] FALSE


[[8]]
[[8]]$value
function () 
{
    is_win <- .Platform$OS.type == "windows"
    options(add.smooth = TRUE, browserNLdisabled = FALSE, CBoundsCheck = FALSE, 
        check.bounds = FALSE, continue = "+ ", contrasts = c(unordered = "contr.treatment", 
            ordered = "contr.poly"), defaultPackages = c("datasets", 
            "utils", "grDevices", "graphics", "stats", "methods"), 
        demo.ask = "default", device = if (is_win) 
            windows
        else x11, device.ask.default = FALSE, digits = 7, echo = TRUE, 
        editor = "internal", encoding = "native.enc", example.ask = "default", 
        expressions = 5000, help.search.types = c("vignette", 
            "demo", "help"), help.try.all.packages = FALSE, help_type = "text", 
        HTTPUserAgent = with(R.version, paste0("R (", paste(major, 
            minor, sep = "."), " ", platform, " ", arch, " ", 
            os, ")")), internet.info = 2, keep.source = TRUE, 
        keep.source.pkgs = FALSE, locatorBell = TRUE, mailer = "mailto", 
        max.print = 99999, menu.graphics = TRUE, na.action = "na.omit", 
        nwarnings = 50, OutDec = ".", pager = "internal", papersize = "a4", 
        pdfviewer = file.path(R.home("bin"), "open.exe"), pkgType = if (is_win) 
            "win.binary"
        else "source", prompt = "> ", repos = c(CRAN = "@CRAN@", 
            CRANextra = "http://www.stats.ox.ac.uk/pub/RWin"), 
        scipen = 0, show.coef.Pvalues = TRUE, show.error.messages = TRUE, 
        show.signif.stars = TRUE, str = list(strict.width = "no", 
            digits.d = 3, vec.len = 4), str.dendrogram.last = "`", 
        stringsAsFactors = TRUE, timeout = 60, ts.eps = 1e-05, 
        ts.S.compat = FALSE, unzip = "internal", useFancyQuotes = TRUE, 
        verbose = FALSE, warn = 0, warning.length = 1000, width = 80, 
        windowsTimeouts = c(100, 500))
}

[[8]]$visible
[1] FALSE


> 
> 
> autolib(rjags)
> autolib(batch)
> autolib(reshape2)
> 
> My.device<-Gen.device("png",res=400,width=12,height=3,units="in")
> 
> source(file.path(script.path,"hindcasting helper functions/DensityEstimator.R"))
> #### Reading in  functions specific for this project 
> lapply((grep("R$",dir(file.path(script.path,"hindcasting\ helper\ functions"),full.names=T),value=T)),source)
[[1]]
[[1]]$value
function (expected.path, errorFun, reps = 1) 
{
    expected.path.long <- do.call("data.frame", lapply(expected.path, 
        rep, reps))
    generated.data <- errorFun(expected.path.long)
    return(generated.data)
}

[[1]]$visible
[1] FALSE


[[2]]
[[2]]$value
function (test.means.array, standard.deviation = log(1.1)) 
{
    if (is.null(ncol(test.means.array))) {
        test.means.array <- array(test.means.array, dim = c(length(test.means.array), 
            1))
    }
    col = 1
    obs.value.array <- apply(test.means.array, 2, function(x) {
        obs.error = rlnorm(length(x), meanlog = 0, sdlog = standard.deviation[col])
        obs.value = obs.error * x
        col <<- ifelse((col + 1) > length(standard.deviation), 
            1, (col + 1))
        return(obs.value)
    })
    return(obs.value.array)
}

[[2]]$visible
[1] FALSE


[[3]]
[[3]]$value
function (n.infections, end.time, peak.time, sd, ...) 
{
    infection.times <- rlnorm(n.infections, meanlog = log(end.time - 
        peak.time), sdlog = log(sd))
    infection.times <- end.time - infection.times
    return(infection.times)
}
<environment: 0x7fb64c0370e0>

[[3]]$visible
[1] FALSE


[[4]]
[[4]]$value
function (sim.name, ma.width = 7, scenario.pars = NULL, ...) 
{
    require(stringr, rjags)
    if (is.character(sim.name)) {
        simresults.name <- load(sim.name)
        results.ndx <- which(sapply(lapply(scenarios.results, 
            names), function(x) any(grepl("est", x))))
        epi.obs <- as.numeric(str_extract(str_extract(sim.name, 
            "endtime\\_[[:digit:]]+"), "[[:digit:]]+"))
        epi.start <- as.numeric(str_extract(str_extract(sim.name, 
            "start|starttime\\_[[:digit:]]+"), "[[:digit:]]+"))
        pert.or.btv <- str_extract(tail(strsplit(sim.name, "/")[[1]], 
            1), "(pert)|(btv)")
        ntests <- str_extract(sim.name, "[[:alpha:]]+test")
        sample.size <- nrow(get(simresults.name)[[results.ndx]]$true.values)
        sim.results <- get(simresults.name)[[results.ndx]]$est
    }
    else {
        sim.results <- sim.name
        for (i in names(scenario.pars)) {
            assign(i, scenario.pars[[i]])
        }
    }
    if (pert.or.btv == "pert" | pert.or.btv == "pertussis") {
        true.curve <- pertussis.wi.Fun(1, start.time = epi.start, 
            end.time = epi.obs, Actual = T)
    }
    if (pert.or.btv == "btv") {
        true.curve <- btv.2008.Fun(1, start.time = epi.start, 
            end.time = epi.obs, Actual = T)
    }
    true.density <- hist(true.curve, breaks = seq(0, epi.obs - 
        epi.start, by = 1), plot = F)$density
    true.density.smooth <- c(cumsum(true.density[1:((ma.width - 
        1)/2)])/(1:((ma.width - 1)/2)), na.omit(filter(true.density, 
        rep(1, ma.width)/ma.width, sides = 2)), (cumsum(tail(true.density, 
        ma.width))/(1:(ma.width)))[((ma.width - 1)/2 + 2):ma.width])
    estimated.density <- lognorm.plotdata.fun(sim.results, df = FALSE, 
        interval.eval = 1, range.eval = (epi.obs - epi.start) * 
            4)
    estimated.density.df <- lognorm.plotdata.fun(sim.results, 
        df = TRUE, interval.eval = 1, range.eval = (epi.obs - 
            epi.start) * 4)
    est.r2 <- cor((true.density), estimated.density[2:(epi.obs - 
        epi.start + 1)])^2
    est.r2.smooth <- cor(true.density.smooth, estimated.density[2:(epi.obs - 
        epi.start + 1)])^2
    est.peaktime <- do.call("c", sim.results[, "peak.time", ])
    est.duration <- do.call("c", sim.results[, "duration", ])
    est.epistart <- qlnorm(1 - 0.5/sum(true.curve), log(est.peaktime), 
        log(est.duration))
    peaktime.50 <- quantile(est.peaktime, 0.5)
    peaktime.05 <- quantile(est.peaktime, 0.05)
    peaktime.95 <- quantile(est.peaktime, 0.95)
    duration.50 <- quantile(est.duration, 0.5)
    duration.05 <- quantile(est.duration, 0.05)
    duration.95 <- quantile(est.duration, 0.95)
    epistart.50 <- quantile(est.epistart, 0.5)
    epistart.95 <- quantile(est.epistart, 0.95)
    epistart.05 <- quantile(est.epistart, 0.5)
    epistart.bias.rel <- quantile((est.epistart)/(epi.obs - epi.start), 
        c(0.05, 0.5, 0.95))[2]
    epistart.bias <- quantile(abs((est.epistart) - (epi.obs - 
        epi.start)), c(0.05, 0.5, 0.95))
    epistart.bias.50 <- epistart.bias[2]
    epistart.bias.05 <- epistart.bias[1]
    epistart.bias.95 <- epistart.bias[3]
    est.absmean <- (mean(abs(sample.size * estimated.density[2:(epi.obs - 
        epi.start + 1)] - sample.size * true.density.smooth)))
    est.rmsep <- sqrt(mean((sample.size * estimated.density[2:(epi.obs - 
        epi.start + 1)] - sample.size * true.density.smooth)^2))
    gelman.convergence <- gelman.diag(sim.results[, c("peak.time", 
        "duration"), ])
    results.df <- data.frame(est.r2 = est.r2, est.r2.smooth = est.r2.smooth, 
        est.rmsep = est.rmsep, epistart.50 = epistart.50, epistart.05 = epistart.05, 
        epistart.95 = epistart.95, epistart.bias.50 = epistart.bias.50, 
        epistart.bias.05 = epistart.bias.05, epistart.bias.95 = epistart.bias.95, 
        epistart.relative.bias = epistart.bias.rel, duration.50 = duration.50, 
        duration.05 = duration.05, duration.95 = duration.95, 
        peaktime.50 = peaktime.50, peaktime.05 = peaktime.05, 
        peaktime.95 = peaktime.95, overall.convergence = gelman.convergence$mpsrf, 
        epi.obs = epi.obs, epi.start = epi.start, pathogen = pert.or.btv, 
        one.or.two = ntests, sample.size = sample.size)
    return(list(results.df = results.df, detailed.results = list(est.r2 = est.r2, 
        bias = epistart.bias, gelman.convergence = gelman.convergence, 
        density = estimated.density.df)))
}

[[4]]$visible
[1] FALSE


[[5]]
[[5]]$value
function (xpos, ypos, tpos, npoints) 
{
    xpos <- xpos[order(tpos)]
    ypos <- ypos[order(tpos)]
    points.dist <- sqrt(diff(xpos)^2 + diff(ypos)^2)
    path.cumlength <- cumsum(points.dist)
    equaldist.cumlength <- seq(0, tail(path.cumlength, 1), length.out = npoints - 
        1)
    stddist <- equaldist.cumlength[2]
    Interpol.points <- list(x = vector(length = npoints, mode = "numeric"), 
        y = vector(length = npoints, mode = "numeric"))
    Interpol.points$x[1] = xpos[1]
    Interpol.points$y[1] = ypos[1]
    for (i in 2:(npoints - 5)) {
        start.point = c(Interpol.points$x[i - 1], Interpol.points$y[i - 
            1])
        ndx <- which(path.cumlength > equaldist.cumlength[i - 
            1] & path.cumlength <= equaldist.cumlength[i + 5])
        x.lm <- xpos[ndx + 1] - start.point[1]
        y.lm <- ypos[ndx + 1] - start.point[2]
        cos.values <- x.lm/sqrt(x.lm^2 + y.lm^2)
        Angle = mean(((y.lm < 0) * 2 * pi) + acos(cos.values) * 
            sign(y.lm))
        Ydist = sin(Angle) * stddist
        Xdist = cos(Angle) * stddist
        Next.point <- start.point + c(Xdist, Ydist)
        Interpol.points$x[i] = Next.point[1]
        Interpol.points$y[i] = Next.point[2]
    }
    Interpol.points <- as.data.frame(Interpol.points)
    Interpol.points <- Interpol.points[!is.na(Interpol.points$x), 
        ]
    Interpol.points <- Interpol.points[!is.na(Interpol.points$y), 
        ]
    Interpol.points <- Interpol.points[!duplicated(Interpol.points), 
        ]
    return(Interpol.points)
}

[[5]]$visible
[1] FALSE


[[6]]
[[6]]$value
function (n = 100, start.time = 0, end.time = NULL, incidence = NULL, 
    SerumDecayFun, NaDecayFun, timeFun, errorFun, reinfect = FALSE, 
    SD = log(1.1), FIX = FALSE, pop.actual = FALSE, ...) 
{
    obs.time <- end.time - start.time
    pop <- vector(length = n, mode = "numeric")
    total.infected <- rpois(1, n * obs.time * incidence)
    if (FIX) {
        total.infected <- n * obs.time * incidence
    }
    if (pop.actual) {
        total.infected <- n
    }
    if (!FIX) 
        infected.ndx <- sort(sample(1:n, total.infected, replace = T))
    if (FIX) 
        infected.ndx <- 1:total.infected
    if (!reinfect) 
        infected.ndx <- unique(infected.ndx)
    number.infections <- aggregate(infected.ndx, list(n.infected = infected.ndx), 
        length)[, 2]
    infected.ndx <- sort(unique(infected.ndx))
    if (reinfect) {
        infection.time <- sapply(number.infections, function(x) max(timeFun(n.infections = x, 
            start.time = start.time, end.time = end.time, ...)))
    }
    if (!reinfect) {
        infection.time <- timeFun(n.infections = length(infected.ndx), 
            start.time = start.time, end.time = end.time, ...)
    }
    antibody.data <- data.frame(index = infected.ndx, number.infections, 
        infection.time = infection.time, antibody.levels = NA, 
        na.result = 0)
    antibody.data <- rbind(antibody.data, data.frame(index = Ndx <- which(!((1:n) %in% 
        infected.ndx)), number.infections = rep(0, length(Ndx)), 
        infection.time = rep(0, length(Ndx)), antibody.levels = rep(0, 
            length(Ndx)), na.result = rep(0, length(Ndx))))
    antibody.data$antibody.levels <- SerumDecayFun(infection.time = antibody.data$infection.time)
    antibody.data$na.result <- NaDecayFun(infection.time = antibody.data$infection.time)
    antibody.data[c("antibody.levels", "na.result")] <- errorFun(antibody.data[c("antibody.levels", 
        "na.result")], standard.deviation = SD)
    return(antibody.data)
}

[[6]]$visible
[1] FALSE


[[7]]
[[7]]$value
function (testkinetic, timeFun, timeFun.args = NULL, errorFun, 
    errorFun.args = NULL, ...) 
{
    infection.times <- do.call("timeFun", c(timeFun.args, ...))
    test.meanvalues <- testkinetic(infection.times)
    test.obsvalues = do.call("errorFun", c(list(test.means.array = test.meanvalues), 
        errorFun.args))
    return(list(infection.times = infection.times, test.meanvalues = test.meanvalues, 
        test.obsvalues = test.obsvalues))
}

[[7]]$visible
[1] FALSE


[[8]]
[[8]]$value
function (incidence = 0.01, trend = 0.01/30, censorLimit = 30, 
    simtype = "population", n.obs = 1000, engine = "nlm", transform.pars = TRUE, 
    type = "ll") 
{
    approx.popsize <- round(n.obs/(censorLimit * (incidence + 
        trend * censorLimit/2)))
    obs.data <- if (simtype == "population") {
        EndemicLinear(approx.popsize, incidence = incidence, 
            trend = trend, start.time = 0, end.time = censorLimit)
    }
    else {
        rlinear.tsi(n.obs, incidence = incidence, trend = trend, 
            censorLimit = censorLimit)
    }
    obs.data <- obs.data[!is.na(obs.data)]
    prior.inc <- exp(censorLimit * log(1 - length(obs.data)/(approx.popsize)))
    pars.est <- nlm(tsi.linear.ll, p = c(log(prior.inc), log((prior.inc)/(censorLimit))), 
        transform.pars = transform.pars, data = obs.data, popsize = approx.popsize, 
        censorLimit. = censorLimit, steptol = 1e-08)
    if (transform.pars) {
        pars.est$estimate[1] <- exp(pars.est$estimate[1])
        pars.est$estimate[2] <- exp(pars.est$estimate[2]) - pars.est$estimate[1]/censorLimit
    }
    return(list(incidence.est = pars.est$estimate[1], trend.est = pars.est$estimate[2], 
        incidence.bias = incidence - pars.est$estimate[1], trend.bias = trend - 
            pars.est$estimate[2]))
}

[[8]]$visible
[1] FALSE


[[9]]
[[9]]$value
function (mcmc.posterior, interval.eval = 1, range.eval = 1000, 
    df = TRUE, use.z = F, ...) 
{
    posterior.allchains <- do.call("rbind", mcmc.posterior)
    if (!use.z) {
        lognorm.density.matrix <- apply(posterior.allchains, 
            1, function(x) {
                dlnorm(seq(0, range.eval, by = interval.eval), 
                  meanlog = log(x["peak.time"]), sdlog = log(x["duration"]))
            })
    }
    if (use.z) {
        X <- seq(0, range.eval, by = interval.eval)
        logMu <- rep(log(posterior.allchains[, "peak.time"]), 
            each = length(X))
        logSD <- rep(log(posterior.allchains[, "duration"]/2), 
            each = length(X))
        X.rep <- rep(X, nrow(posterior.allchains))
        Z <- (X.rep/exp(logMu))^(1/logSD)
        scaling.log <- (log(X.rep) - logMu)/logSD - log(X.rep) - 
            log(logSD)
        x.rawdensity <- dlnorm(Z, log = T)
        x.density <- x.rawdensity + scaling.log
        x.density[X == 0] <- -Inf
        lognorm.density.matrix <- matrix(exp(x.density), ncol = nrow(posterior.allchains), 
            nrow = length(X))
    }
    density.quantile <- apply(lognorm.density.matrix, 1, quantile, 
        c(0.05, 0.5, 0.95))
    if (df == TRUE) {
        density.quantile[, 2]
        if (df) {
            lognorm.density.df <- data.frame(duration = seq(0, 
                range.eval, by = interval.eval), density = density.quantile[2, 
                ], density.95 = density.quantile[3, ], density.0.05 = density.quantile[1, 
                ])
            return(lognorm.density.df)
        }
    }
    if (!df) {
        return(rowMeans(lognorm.density.matrix))
    }
}

[[9]]$visible
[1] FALSE


[[10]]
[[10]]$value
NULL

[[10]]$visible
[1] FALSE


[[11]]
[[11]]$value
[1] "time" "abt"  "nat" 

[[11]]$visible
[1] FALSE


> 
> 
> ########################
> ###Default parameters ##
> ########################
> 
> ### MCMC parameters 
> seed=1000
> adapt.iter=100
> n.chains.=5
> mcmc.ss=100
> thin=1
> 
> ###Other run parameters
> converge<-F
> converge.criteria<-1.15
> converge.time=0.2
> rep.prefix=NULL
> nreps=0
> 
> ###Epidemic trend pars
> Epi.scenario="EndemicConstantFixedSD" ##EndemicLinear EpidemicExp EpidemicLognorm
> Epi.scenario="EndemicLinear"
> Epi.model="EndemicLinear"
> Start.time=0
> End.time=30
> Incidence=1/100
> samplesize= 1000
> ##Par for linear and exponential trend
> Trend=0.01/50
> Peak.time=15
> Epi.sd=10
> 
> 
> 
> ##Pars releveant for trends modelled on true outbreaks
> Actual.=T
> pathogen="btv" #or "pertussis"
> 
> ##Test value generator parameters 
> diseaseType="diseaseType2" ##diseaseType1 diseaseType3
> n.tests="Both"
> test1.sd=1.27
> test2.sd=1.57
> 
> 
> 
> 
> ###Alternatively, reading in all parameters from a batch call (how many pars can you pass?)
> parseCommandArgs()
$seed
[1] 1000

$burn.in
[1] 100

$adapt.iter
[1] 50

$n.chains.
[1] 5

$mcmc.ss
[1] 100

$thin
[1] 10

$converge
[1] "FALSE"

$converge.criteria
[1] 1.15

$converge.time
[1] 0.2

$diseaseType
[1] "diseaseType1"

$samplesize
[1] 100

$start.time
[1] 0

$Start.time
[1] 0

$End.time
[1] 10

$Incidence
[1] 0.1

$Trend
[1] -0.005

$Epi.scenario
[1] "EndemicLinear"

$change.percent
[1] -0.5

$rep.prefix
[1] 0

$nreps
[1] 0

$ncores
[1] 8

$test1.sd
[1] 1.3

$test2.sd
[1] 1.3

$n.tests
[1] "Ab"

> set.seed(seed)
> 
> 
> 
> ##LV.Fun accepts a list of parameters specific to the disease type. get() gets this list.
> kinetic.fun=LotkaVolterra.Fun(disease=get(diseaseType))
> measurement.sd=c(test1.sd=test1.sd,test2.sd=test2.sd)
> 
> 
> ####################################################################
> ######## setting parameters for the different scenarios ############
> ####################################################################
> 
> 
> 
> #Constant trend args
> if(Epi.scenario=="EndemicLinear"){
+   scenario.args=list(n.infection=samplesize,
+                      start.time=Start.time,
+                      end.time=End.time,
+                      incidence=Incidence,
+                      trend=Trend)
+   modelscript.name="bugs/hindcast_linear_proppos.txt"
+   sample.vars=c("incidence","trend","sd","mean.incidence","InfTime")
+   Epi.model="EndemicLinear"
+ }else{if(Epi.scenario%in%c("EndemicConstant","EndemicIncrease","EndemicDecrease")){
+ ##Linear trend args
+ scenario.args=list(n.infection=samplesize,
+                    start.time=Start.time,
+                    end.time=End.time,
+                    incidence=Incidence,
+                    trend=Trend)
+ modelscript.name="bugs/hindcast_linear_proppos.txt"
+ sample.vars=c("incidence","trend","sd","InfTime")
+ Epi.model="EndemicLinear"
+ }else{
+     if(Epi.scenario%in%c("EndemicConstantFixedSD","EndemicIncreaseFixedSD","EndemicDecreaseFixedSD")){
+       ##Linear trend args
+       scenario.args=list(n.infection=samplesize,
+                          start.time=Start.time,
+                          end.time=End.time,
+                          incidence=Incidence,
+                          trend=Trend)
+       modelscript.name="bugs/hindcast_linear_fixedSD_proppos.txt"
+       sample.vars=c("incidence","trend","mean.incidence","InfTime")
+       Epi.model="EndemicLinear"
+     }else{
+ ##Exponential trend args
+   if(Epi.scenario=="EpidemicExp"){
+ scenario.args=list(n.infection=samplesize,
+                    start.time=Start.time,
+                    end.time=End.time,
+                    trend=Trend)
+ modelscript.name="bugs/hindcast_exponential.txt"
+ sample.vars=c("trend")
+ Epi.model="EpidemicExp"
+ 
+ }else{
+   if(Epi.scenario=="EndemicKnownTimes"){
+   modelscript.name="bugs/hindcast_linear_knowntimes.txt"
+   scenario.args=list(n.infection=samplesize,
+                      start.time=Start.time,
+                      end.time=End.time,
+                      incidence=Incidence,
+                      trend=Trend)
+   sample.vars=c("incidence","trend","mean.incidence","InfTime")
+   Epi.model="EndemicLinear"
+   
+ }else{
+ ##lognorm trend args 
+ scenario.args=list(n.infection=samplesize,
+                    start.time=Start.time,
+                    end.time=End.time,
+                    peak.time=Peak.time,
+                    sd=Epi.sd)
+                  
+ Epi.model="EpidemicLognorm"
+ 
+ modelscript.name="bugs/hindcast_lognorm.txt"
+ sample.vars=c("peak.time","duration")
+ }}}}}
> ##############################
> 
> #### Step.data (and likelihood!)
> 
> 
> scenarios.results<-vector(mode="list",length=0)
> 
> peak<-ifelse(diseaseType=="diseaseType1",5,
+              ifelse(diseaseType=="diseaseType2",5,5)
+              ) ##change this to line of least likelihood
> n.test<-if(n.tests=="Ab"){1}else{
+   if(n.tests=="NA"){2}else{
+     if(n.tests=="Both"){1:2}else{
+       stop(simpleError("Wrong n. of tests!"))
+     }}}
> censorLimit=End.time-Start.time
> 
> for(i in 0:nreps){
+   
+   t0<-proc.time()
+   iteration.data<-
+     LabdataGeneratorGeneric(
+       testkinetic=kinetic.fun,
+       timeFun= get(Epi.model),
+       timeFun.args=scenario.args,
+       errorFun=errorFun.lognorm,
+       errorFun.args=list(standard.deviation=log(measurement.sd))
+     )
+   n.sampled<-length(iteration.data$infection.times)
+   iteration.data<-lapply(iteration.data,function(x){if(!is.null(ncol(x))){x[is.finite(iteration.data$infection.times),]}else{x[is.finite(iteration.data$infection.times)]}})
+   iteration.data$n.sampled<-n.sampled
+   iteration.data$PropAboveCensor<-(n.sampled-length(iteration.data$infection.times))/n.sampled
+   ###########################################################
+   ##### Generating inits and bugs pars below here ###########
+   ###########################################################
+   
+   
+   if(Epi.scenario=="EndemicLinear"){
+     ##Linear trend args
+     bugs.args=list(censorLimit=End.time-Start.time,
+                    is.naive=is.na(iteration.data$test.obsvalues[,1])
+     )
+     inits.list<-vector(mode="list",length=n.chains.)
+     for(C in 1:n.chains.){
+       inits.list[[C]]=list(
+         prepeak=sample(c(0,1),nrow(iteration.data$test.obsvalues),replace=TRUE),
+         Prepeak.time=runif(nrow(iteration.data$test.obsvalues),0,peak),
+         Postpeak.time=runif(nrow(iteration.data$test.obsvalues),peak,End.time-Start.time),
+         mean.incidence.tmp=runif(1,Incidence/2,Incidence*1.5),
+         trend=runif(1,-abs(Incidence/(2*End.time)),abs(Incidence/(2*End.time))),
+         sd.exp.tmp=rexp(length(n.test),1/0.05)+1)
+     }
+   }else{
+   if(Epi.scenario%in%c("EndemicConstant","EndemicIncrease","EndemicDecrease")){
+     ##Linear trend args
+     bugs.args=list(censorLimit=End.time-Start.time,
+                    is.naive=is.na(iteration.data$test.obsvalues[,1])
+     )
+     inits.list<-vector(mode="list",length=n.chains.)
+     for(C in 1:n.chains.){
+       inits.list[[C]]=list(
+           InfTime=ifelse(is.na(iteration.data$test.obsvalues[,1]),
+                        35,runif(nrow(iteration.data$test.obsvalues),0,End.time-Start.time)),
+         incidence=runif(1,0.01,0.3),
+         trend=runif(1,-0.01/35,0.01/35))
+     }
+   }else{
+     if(Epi.scenario%in%c("EndemicConstantFixedSD","EndemicIncreaseFixedSD","EndemicDecreaseFixedSD")){
+       ##Linear trend args
+        bugs.args=list(censorLimit=End.time-Start.time,
+                      is.naive=is.na(iteration.data$test.obsvalues[,1]),
+                      sd=c(test1.sd,test2.sd),
+                      peak=peak
+       )
+       inits.list<-vector(mode="list",length=n.chains.)
+       for(C in 1:n.chains.){
+         inits.list[[C]]=list(
+           prepeak=sample(c(0,1),nrow(iteration.data$test.obsvalues),replace=TRUE),
+           Prepeak.time=runif(nrow(iteration.data$test.obsvalues),0,peak),
+           Postpeak.time=runif(nrow(iteration.data$test.obsvalues),peak,End.time-Start.time),
+           mean.incidence.tmp=runif(1,0.3,1),
+           trend=runif(1,-0.01,0.01)/15)
+       }
+     }else{
+       ##Exponential trend args
+       if(Epi.scenario=="EpidemicExp"){
+         bugs.args=list()
+         inits.list=list()
+         
+         
+       }else{
+         if(Epi.scenario=="EndemicKnownTimes"){
+           ##Linear trend args
+           bugs.args=list(censorLimit=End.time-Start.time,
+                          is.naive=is.na(iteration.data$test.obsvalues[,1]),
+                          InfTime=iteration.data$infection.times,
+                          sd=c(test1.sd,test2.sd)
+           )
+           inits.list<-vector(mode="list",length=n.chains.)
+           for(C in 1:n.chains.){
+             inits.list[[C]]=list(
+               mean.incidence.tmp=runif(1,0.3,1),
+               trend=runif(1,-0.01,0.01)/15)
+           }
+         }else{
+         ##lognorm trend args 
+         bugs.args=list()
+         inits.list=list(peak.time=rgamma(1,4,scale=End.time/4),
+                         duration.tmp=abs(rt(1,5))
+         )
+         
+       }}}}}
+   ##########################################
+   ##########################################
+                       
+   bugsdata<-c(list(N=nrow(iteration.data$test.obsvalues),
+                    NTot=iteration.data$n.sampled,
+                    Test.data=iteration.data$test.obsvalues[,n.test,drop=FALSE],
+                    time.lookup=c(seq(0.5,99.5,by=0.5)),
+                    test.lookup=kinetic.fun(c(seq(0.5,99.5,by=0.5)))[,n.test,drop=FALSE],
+                    ntest=length(n.test),peak=peak
+               ),bugs.args)
+   pars.inits<-vector(length=n.chains.,mode="list")
+   for(C in 1:n.chains.){
+     pars.inits[[C]]<-c(inits.list[[C]][-4]
+                       # list(logsd.tmp=rep(runif(1,log(1.02),log(4)),n.tests))
+     )
+   }
+   
+   
+   multitest.bugs<-jags.model(file=file.path(script.path,modelscript.name),
+                              data=bugsdata,
+                              inits=pars.inits,
+                              n.adapt=0,
+                              n.chains=n.chains.)
+   
+   possibleError1<-tryCatch(adapt(multitest.bugs,adapt.iter),
+                            error=function(e) e )
+   
+   gelman.current<-Inf
+   start.time<-proc.time()
+   elapsed.time<-0
+   while(((gelman.current>converge.criteria)&(elapsed.time<converge.time))){
+     
+     possibleError2<-tryCatch(update(multitest.bugs,burn.in),
+                              error=function(e) e)
+     if(!(inherits(possibleError1, "error")|inherits(possibleError2, "error"))){
+       iteration.samples<-coda.samples(multitest.bugs,variable.names=sample.vars,mcmc.ss,thin=thin)
+     }
+     #gelman.current<-mean(gelman.diag(iteration.samples[,grep(paste(sample.vars[-which(sample.vars=="InfTime")],collapse="|"),colnames(iteration.samples[[1]])),drop=FALSE])$psrf[,1])
+     
+     print("current convergence: ")
+     print(gelman.current)
+     print("\n")
+     if(converge==F){gelman.current<-1}
+     elapsed.time<-(proc.time()-start.time)[3]/3600 
+     print(elapsed.time)
+   }
+   scenarios.results$true.values<-iteration.data
+   scenarios.results$est<-iteration.samples
+   
+   
+   scenarios.results$pars.inits<-pars.inits
+   scenarios.results$control.vars<-c(modelscript.name=modelscript.name,
+                                     scenario.args,
+                                     Epi.model=Epi.model)
+   scenarios.results$time<-Sys.time()
+   
+   if((inherits(possibleError1, "error")|inherits(possibleError2, "error"))){
+     scenarios.results$est<-FALSE
+     scenarios.results$error<-c(possibleError1,possibleError2)
+   }  
+   
+   print(i) 
+   save(scenarios.results,file=paste(
+     sim.dir,Epi.scenario,
+     "_",diseaseType,
+     "_seed",seed,
+     "_",n.tests,"test",
+     paste("_samplesize",samplesize,sep=""),
+     "_","dur",End.time,
+     "_Inc",Incidence,"_Change",change.percent,"pc",
+     "_",rep.prefix,i,
+     ".RData",sep=""))
+ }
Compiling data graph
   Resolving undeclared variables
   Allocating nodes
   Initializing
   Reading data back into data table
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 3146

Initializing model

NOTE: Stopping adaptation


[1] "current convergence: "
[1] Inf
[1] "\n"
    elapsed 
0.001675278 
[1] 0
> 
